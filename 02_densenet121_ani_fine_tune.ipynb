{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# DenseNet121을 이용한 애니메이션 표정 분류 Fine-tuning 실험\n",
        "\n",
        "# 1. 필요한 라이브러리 임포트 및 환경 설정\n",
        "from google.colab import drive\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms, models, datasets\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# Google Drive 마운트 및 기본 설정\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 필요한 패키지 설치\n",
        "%pip install torch torchvision tqdm pandas matplotlib\n",
        "\n",
        "# 프로젝트 디렉토리 설정\n",
        "project_path = '/content/drive/MyDrive/Final'\n",
        "os.chdir(project_path)\n",
        "\n",
        "# 디렉토리 구조 설정\n",
        "dirs = {\n",
        "    'model': os.path.join(project_path, 'model'),\n",
        "    'result': os.path.join(project_path, 'result'),\n",
        "    'plots': os.path.join(project_path, 'plots'),\n",
        "    'data': {\n",
        "        'train': os.path.join(project_path, 'ani/train'),\n",
        "        'val': os.path.join(project_path, 'ani/val')\n",
        "    }\n",
        "}\n",
        "\n",
        "# 필요한 디렉토리 생성\n",
        "for dir_path in [dirs['model'], dirs['result'], dirs['plots']]:\n",
        "    if not os.path.exists(dir_path):\n",
        "        os.makedirs(dir_path)\n",
        "\n",
        "# 장치 설정\n",
        "device = torch.device('cuda')\n",
        "\n",
        "# 2. 데이터 전처리 및 증강 설정\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomRotation(15),\n",
        "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "}\n",
        "\n",
        "# 데이터셋 로드\n",
        "train_dataset = datasets.ImageFolder(dirs['data']['train'], transform=data_transforms['train'])\n",
        "val_dataset = datasets.ImageFolder(dirs['data']['val'], transform=data_transforms['val'])\n",
        "\n",
        "# 클래스 정보 출력\n",
        "print(\"\\n데이터셋 정보:\")\n",
        "print(\"클래스:\", train_dataset.classes)\n",
        "print(\"클래스 수:\", len(train_dataset.classes))\n",
        "print(\"학습 데이터 수:\", len(train_dataset))\n",
        "print(\"검증 데이터 수:\", len(val_dataset))\n",
        "\n",
        "# 데이터로더 생성\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "# 3. DenseNet121 모델 설정 및 학습\n",
        "def setup_densenet121(num_classes):\n",
        "    \"\"\"DenseNet121 모델 설정\"\"\"\n",
        "    model = models.densenet121(pretrained=True)\n",
        "    \n",
        "    # 특성 추출기의 파라미터 고정\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "    \n",
        "    # 분류기 층 수정\n",
        "    num_ftrs = model.classifier.in_features\n",
        "    model.classifier = nn.Sequential(\n",
        "        nn.Linear(num_ftrs, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.5),\n",
        "        nn.Linear(512, num_classes)\n",
        "    )\n",
        "    \n",
        "    return model.to(device)\n",
        "\n",
        "def train_model(model, criterion, optimizer, num_epochs=25):\n",
        "    \"\"\"모델 학습 함수\"\"\"\n",
        "    best_acc = 0.0\n",
        "    results = {\n",
        "        'train_loss': [], 'train_acc': [],\n",
        "        'val_loss': [], 'val_acc': []\n",
        "    }\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'\\nEpoch {epoch+1}/{num_epochs}')\n",
        "        print('-' * 10)\n",
        "        \n",
        "        # 학습 단계\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "        \n",
        "        for inputs, labels in tqdm(train_loader, desc='Training'):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            with torch.set_grad_enabled(True):\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                loss = criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "            \n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "        \n",
        "        epoch_loss = running_loss / len(train_dataset)\n",
        "        epoch_acc = running_corrects.double() / len(train_dataset)\n",
        "        results['train_loss'].append(epoch_loss)\n",
        "        results['train_acc'].append(epoch_acc.item())\n",
        "        \n",
        "        print(f'Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "        \n",
        "        # 검증 단계\n",
        "        model.eval()\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "        \n",
        "        for inputs, labels in tqdm(val_loader, desc='Validation'):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            \n",
        "            with torch.no_grad():\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                loss = criterion(outputs, labels)\n",
        "            \n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "        \n",
        "        epoch_loss = running_loss / len(val_dataset)\n",
        "        epoch_acc = running_corrects.double() / len(val_dataset)\n",
        "        results['val_loss'].append(epoch_loss)\n",
        "        results['val_acc'].append(epoch_acc.item())\n",
        "        \n",
        "        print(f'Val Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "        \n",
        "        # 최고 성능 모델 저장\n",
        "        if epoch_acc > best_acc:\n",
        "            best_acc = epoch_acc\n",
        "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'loss': epoch_loss,\n",
        "                'acc': epoch_acc,\n",
        "            }, os.path.join(dirs['model'], f'densenet121_best_{timestamp}.pt'))\n",
        "        \n",
        "\n",
        "    \n",
        "    # 최종 결과 저장\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    pd.DataFrame(results).to_csv(os.path.join(dirs['result'], f'densenet121_results_{timestamp}.csv'))\n",
        "    \n",
        "    return results\n",
        "\n",
        "# 모델 학습 실행\n",
        "print(\"\\nDenseNet121 모델 학습 시작\")\n",
        "model = setup_densenet121(len(train_dataset.classes))\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.classifier.parameters(), lr=0.001)\n",
        "\n",
        "results = train_model(model, criterion, optimizer)\n",
        "\n",
        "# 4. 결과 시각화\n",
        "def plot_training_results(results):\n",
        "    \"\"\"학습 결과 시각화\"\"\"\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    \n",
        "    # 전체 그래프 (Loss와 Accuracy)\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "    \n",
        "    # 손실 그래프\n",
        "    ax1.plot(results['train_loss'], label='Train')\n",
        "    ax1.plot(results['val_loss'], label='Validation')\n",
        "    ax1.set_title('Loss over epochs')\n",
        "    ax1.set_xlabel('Epoch')\n",
        "    ax1.set_ylabel('Loss')\n",
        "    ax1.legend()\n",
        "    \n",
        "    # 정확도 그래프\n",
        "    ax2.plot(results['train_acc'], label='Train')\n",
        "    ax2.plot(results['val_acc'], label='Validation')\n",
        "    ax2.set_title('Accuracy over epochs')\n",
        "    ax2.set_xlabel('Epoch')\n",
        "    ax2.set_ylabel('Accuracy')\n",
        "    ax2.legend()\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    \n",
        "    # 전체 그래프 저장\n",
        "    plt.savefig(os.path.join(dirs['plots'], f'densenet121_combined_{timestamp}.png'))\n",
        "    plt.show()\n",
        "    \n",
        "    # Loss 그래프 따로 저장\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.plot(results['train_loss'], label='Train')\n",
        "    plt.plot(results['val_loss'], label='Validation')\n",
        "    plt.title('Loss over epochs')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(dirs['plots'], f'densenet121_loss_{timestamp}.png'))\n",
        "    plt.close()\n",
        "    \n",
        "    # Accuracy 그래프 따로 저장\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.plot(results['train_acc'], label='Train')\n",
        "    plt.plot(results['val_acc'], label='Validation')\n",
        "    plt.title('Accuracy over epochs')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(dirs['plots'], f'densenet121_accuracy_{timestamp}.png'))\n",
        "    plt.close()\n",
        "\n",
        "# 결과 시각화 및 최종 성능 출력\n",
        "print(\"\\n학습 결과:\")\n",
        "plot_training_results(results)\n",
        "print(f\"\\n최종 성능:\")\n",
        "print(f\"최종 학습 정확도: {results['train_acc'][-1]:.4f}\")\n",
        "print(f\"최종 검증 정확도: {results['val_acc'][-1]:.4f}\")\n",
        "print(f\"최고 검증 정확도: {max(results['val_acc']):.4f}\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# DenseNet121을 이용한 애니메이션 표정 분류 Fine-tuning\n",
        "\n",
        "이 노트북은 DenseNet121 모델을 사용하여 애니메이션 캐릭터의 표정을 분류하는 전이학습 실험을 포함합니다.\n",
        "\n",
        "## 실험 구성\n",
        "1. 데이터 전처리 및 증강\n",
        "2. DenseNet121 모델 Fine-tuning\n",
        "3. 실험 결과 분석\n",
        "\n",
        "## 환경 설정\n",
        "- Google Colab 환경\n",
        "- GPU 가속 사용\n",
        "- Google Drive 연동\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
